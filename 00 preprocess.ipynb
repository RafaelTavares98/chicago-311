{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b738ac",
   "metadata": {},
   "source": [
    "## **Objetive**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be912d48",
   "metadata": {},
   "source": [
    "#### **objective**: `data.parquet`\n",
    "\n",
    "- Historical dataset covering the period from 2018-07-01 to 2026-02-08  \n",
    "- Source format: CSV files (mostly one-year batches)  \n",
    "- Each batch: ~1.8M rows Ã— 39 columns  \n",
    "- Goal:\n",
    "  - Apply only minimal and necessary preprocessing  \n",
    "  - Stack all yearly batches into a single unified dataset  \n",
    "  - Export the consolidated result as `data.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657da5b",
   "metadata": {},
   "source": [
    "## **Loading and Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232253ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIG] DATA_DIR=data\\raw | OUTPUT_FILE=data\\processed\\stack.csv\n"
     ]
    }
   ],
   "source": [
    "# Imports & Configuration\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import duckdb as db\n",
    "\n",
    "con = db.connect()\n",
    "DATA_DIR = Path('data/raw')\n",
    "OUTPUT_FILE = Path('data/processed/stack.csv')\n",
    "\n",
    "print(f'[CONFIG] DATA_DIR={DATA_DIR} | OUTPUT_FILE={OUTPUT_FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a400de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\raw\\20 and under 2004970 rows.csv\n",
      "data\\raw\\21-19 1940164 rows.csv\n",
      "data\\raw\\21-20 2018176 rows.csv\n",
      "data\\raw\\22-21 1821488 rows.csv\n",
      "data\\raw\\23-22 1772092 rows.csv\n",
      "data\\raw\\24-23 1818726 rows.csv\n",
      "data\\raw\\25-24 1884950 rows.csv\n",
      "data\\raw\\26-25 1980801 rows.csv\n",
      "Total: 8 CSV files found\n"
     ]
    }
   ],
   "source": [
    "# Filesystem preparation\n",
    "\n",
    "def ensure_output_dir(path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def list_csv_files(data_dir: Path) -> list[Path]:\n",
    "    files = sorted(data_dir.glob('*.csv'))\n",
    "    assert files, 'No CSV files found'\n",
    "    return files\n",
    "\n",
    "\n",
    "ensure_output_dir(OUTPUT_FILE)\n",
    "files = list_csv_files(DATA_DIR)\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    print(file)         \n",
    "\n",
    "print(f'Total: {len(files)} CSV files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea97cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e200bef0518455ca18393692de18398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 1/8]20 and under 2004970 rows.csv | rows=2004970 | cols=39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d1c74bdb6a4ebc9f9eaffccda81308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 2/8]21-19 1940164 rows.csv | rows=1940164 | cols=39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ee46ea037c4cccb7978041b80fbacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 3/8]21-20 2018176 rows.csv | rows=2018176 | cols=39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7007e71662194530829bb8f00eb83030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 4/8]22-21 1821488 rows.csv | rows=1821488 | cols=39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad11d3dac8f43069a16f8339abe1ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 5/8]23-22 1772092 rows.csv | rows=1772092 | cols=39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741adb6a22c64a3e895540518faa5d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 6/8]24-23 1818726 rows.csv | rows=1818726 | cols=39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4612ba41274066975fea202f959652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 7/8]25-24 1884950 rows.csv | rows=1884950 | cols=39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0e094debdd40a29b6ef5747be920ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCAN 8/8]26-25 1980801 rows.csv | rows=1980801 | cols=39\n",
      "[SCAN] Completed. Files scanned: 8\n"
     ]
    }
   ],
   "source": [
    "# Scan each file schema\n",
    "def scan_file(con: db.DuckDBPyConnection, file: Path):\n",
    "    df = con.execute(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM read_csv_auto('{file}', sample_size=-1)\n",
    "    \"\"\").df()\n",
    "    return set(df.columns), len(df)\n",
    "\n",
    "schemas = []\n",
    "row_counts = {}\n",
    "\n",
    "for i, file in enumerate(files, start=1):\n",
    "    cols, n_rows = scan_file(con, file)\n",
    "    schemas.append(cols)\n",
    "    row_counts[file.name] = n_rows\n",
    "\n",
    "    print(\n",
    "        f'[SCAN {i}/{len(files)}]'\n",
    "        f'{file.name} | rows={n_rows} | cols={len(cols)}'\n",
    "    )\n",
    "\n",
    "print(f'[SCAN] Completed. Files scanned: {len(schemas)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426c530f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8923bfaaf756432daec4f07d91f78caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXPORT] file=data\\processed\\stack.csv\n",
      "[EXPORT] rows=15241367 | cols=39\n"
     ]
    }
   ],
   "source": [
    "# Consolidate CSV files into a single stack.csv using common columns\n",
    "\n",
    "def consolidate_csvs(files: list[Path], schemas: list[set], con, output: Path, row_counts: dict):\n",
    "\n",
    "    # determine common columns\n",
    "    common_fields = sorted(set.intersection(*schemas))\n",
    "    assert common_fields, \"No common columns across files\"\n",
    "\n",
    "    # build UNION ALL query\n",
    "    union_query = \" UNION ALL \".join(\n",
    "        [\n",
    "            f'SELECT {\", \".join(common_fields)} '\n",
    "            f'FROM read_csv_auto(\"{f}\", SAMPLE_SIZE=-1)'\n",
    "            for f in files\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # export consolidated file\n",
    "    con.execute(f\"\"\"\n",
    "        COPY (\n",
    "            {union_query}\n",
    "        )\n",
    "        TO '{output}'\n",
    "        WITH (HEADER, DELIMITER ',');\n",
    "    \"\"\")\n",
    "\n",
    "    \n",
    "\n",
    "    # sanity check\n",
    "    total_rows = sum(row_counts.values())\n",
    "\n",
    "    print(f\"[EXPORT] file={output}\")\n",
    "    print(f\"[EXPORT] rows={total_rows} | cols={len(common_fields)}\")\n",
    "\n",
    "\n",
    "consolidate_csvs(files, schemas, con, OUTPUT_FILE, row_counts)\n",
    "\n",
    "# initial stack in csv -> read_csv_auto will be used later to automatically read types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41584165",
   "metadata": {},
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3814c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ee952185cd42f38633fef4197a80e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x24a42117130>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting high missingness % columns to VARCHAR (preventing possible coalescing from read_csv_auto)\n",
    "varchar_cols = {\n",
    "    'LEGACY_SR_NUMBER': 'VARCHAR',\n",
    "    'SANITATION_DIVISION_DAYS': 'VARCHAR',\n",
    "    'PARENT_SR_NUMBER': 'VARCHAR',\n",
    "    'ELECTRICAL_DISTRICT': 'VARCHAR',\n",
    "    'CREATED_DEPARTMENT': 'VARCHAR',\n",
    "    'CITY': 'VARCHAR',\n",
    "    'STATE': 'VARCHAR',\n",
    "    'ELECTRICITY_GRID': 'VARCHAR',\n",
    "    'ZIP_CODE': 'VARCHAR'\n",
    "}\n",
    "\n",
    "df = con.execute(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_csv_auto(\n",
    "        '{OUTPUT_FILE}',\n",
    "        sample_size=-1,\n",
    "        timestampformat='%Y-%m-%d %H:%M:%S',\n",
    "        types={varchar_cols})\n",
    "\"\"\").df()\n",
    "\n",
    "\n",
    "# (df.isna().mean().sort_values(ascending=False).head(25) * 100).round(decimals=2)\n",
    "\n",
    "con.register(\"df_view\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b1410d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c39618815f94b6ba743228191f0eeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x24a42117130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "    COPY df_view\n",
    "    TO 'data/processed/data.parquet'\n",
    "    (FORMAT PARQUET)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aefd311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-08\n",
      "2018-07-01\n"
     ]
    }
   ],
   "source": [
    "max_min = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        MAX(CREATED_DATE) AS max_date,\n",
    "        MIN(CREATED_DATE) AS min_date\n",
    "    FROM read_parquet('data/processed/data.parquet')\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(max_min[0].strftime(\"%Y-%m-%d\"))\n",
    "print(max_min[1].strftime(\"%Y-%m-%d\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
